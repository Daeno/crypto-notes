\course{Complexity Reading Group}{"How to Simulate It" Notes}{Kai-Ming, Chung}{Yin-Hsun, Huang}
\vspace*{4mm} 

\section{Introduction}
Simulation is a way of comparig what happens in the "real world" to what happens in an "ideal world" where the primitive in question is {\it secure by definition}. We start our discussion from semantic security of an private-key encryption. And move on to two-party computation. The semi-honest adversary model is relativly easy and is discussed in Section 4. The rest of article focus on the malicious adversary model.

\vspace{4mm}
\begin{tabular}{|l|c|c|}
\hline
Functionality & Input & Output\\
\hline
(Sec. 5) Zero Knowledge & X & X\\
(Sec. 6) Coin Tossing & X & O \\
(Sec. 7) Oblivious Transfer & O & O \\
\hline
\end{tabular}

\section{Preliminaries and Notation}
\YHnote{Lindel made some discussion on the order of quantifiers for computational indistinguishability. I should elaborate it.}

\section{Semantic Security}
We begin by recalling the definition of semantic security.
\begin{definition}[Semantic Security] A {\it private-key encryption scheme} $(G,E,D)$ is {\bf semantically secure} (in the private-key model) if for every non-uniform probabilistic-polynomial time algorithm $\calA$, there exists a non-uniform probabilistic-polynomial time algorithm $\calA'$ such that for every probability ensemble $\{X_n\}_{n\in\N}$ with $\abs{X_n}\leq poly(n)$, every pair of polynomially-bounded functions $f,h:\{0,1\}^*\to\{0,1\}^*$, every positive polynomial $p(\cdot)$ and all sufficiently large $n$:
\begin{align*}
    \Pr[k\leftarrow G(1^n);\calA(1^n,E_k(X_n), h(1^n,X_n)) = f(1^n, X_n)] \\
    < \Pr[\calA'(1^n,1^{\abs{X_n}}, h(1^n,X_n)) = f(1^n,X_n) ]+ \frac{1}{p(n)}
\end{align*}
with probability over $X_n$ and the randomness of $(G,E)$ and $\calA$ or$\calA'$.
\end{definition}
Though the definition of {\it semantic security} is not directly related to simulation-based paradigm. In particular, $\calA'$ simulate the execution of $\calA$ as follows:
\begin{description}
    \item [\bf Simulator $\calA'$:] Upon input $1^n,h=h(1^n,X_n)$, algorithm $\calA'$ works as follows
    \begin{enumerate}
        \item $\calA'$ runs $G(1^n)$ in order to receive $k$.
        \item $\calA'$ computes $c=E_k(0^{\abs{X_n}})$
        \item $\calA'$ outputs $\calA(1^n,c,a^{\abs{X_n}},h)$
    \end{enumerate}
\end{description}
If encryptions are {\it indistinguishable}, then the simulation process should output the same as $\calA$ with approximately the same probability.
\section{Secure Computation - Semi-Honest Adversaries}
\subsection{Background}
The {\it semi-honest adversaries} in two-party computation is an adversary that follows the protocol but wants to learn information from the transcript of messages. Hence the nickname, honest-but-curious adversaries. 
\begin{remark}
    This is a very weak adversary model. There are no guarantees to the security against adversaries that deviate from the protocol.
\end{remark}

\begin{definition}[Two-party computation] A two-party random process maps pairs of inputs to pairs of outputs. We refer to such a process as a {\bf functionality} and denote it $f:\{0,1\}^*\times\{0,1\}^*\to\{0,1\}^*\times\{0,1\}^*$, where $f=(f_1,f_2)$. For every pair of inputs $x,y\in\{0,1\}^n$, the pair of output is a random variable $(f_1(x,y),f_2(x,y))$. The first (resp. second) party (with input $x$ (resp. $y$)) wishes to obtain $f_1(x,y)$ (resp. $f_2(x,y)$).
\end{definition}
The goal of simulator is to generate the view only from a party's input and output. The security here is formalized by saying that a party's view in a protocol execution be simulatable given only its input and output. 
\begin{description}
\item[Definition of security.] We begin with the following notation:
\begin{itemize}[leftmargin=0em]
    \item Let $f=(f_1,f_2)$ be a PPT functionality and let $\pi$ be a two-party protocol for computing $f$.
    \item The view of the $i$th, where $i=1$ (resp. $i=2$), party is ${\sf view}^\pi_i(x,y,n)$ and equals $(w,r^i;m^i_1,\cdots,m^i_t)$, where $w=x$ (resp. $w=y$). $r^i$ is the internal randomness of $i$th party and $m^i_\ell$ is the $\ell$th message that $i$th party received.
    \item The output of the $i$th party is denoted by $\out^\pi_i(x,y,n)$. We denote the joint output of both parties by $\out^\pi(x,y,n)=(\out^\pi_1(x,y,n))(\out^\pi_2(x,y,n))$.
\end{itemize}
\end{description}
\begin{definition}Let $f=(f_1,f_2)$ be a functionality. We say that {\sf$\pi$ securely computes $f$ in the presence of static semi-honest adversarits} if there exists PPT algorithm $\calS_1$ and $\calS_2$ such that
\begin{align*}
    \{(\calS_1(1^n,x,f_1(x,y)), f(x,y))\}_{x,y,n} \stackrel{c}{\equiv} \{(\view^\pi_1(x,y,n),\out^\pi(x,y,n))\}_{x,y,n} \\
    \{(\calS_2(1^n,x,f_2(x,y)), f(x,y))\}_{x,y,n} \stackrel{c}{\equiv} \{(\view^\pi_2(x,y,n),\out^\pi(x,y,n))\}_{x,y,n}
\end{align*}
where $x,y\in\{0,1\}^*$ such that $\abs{x} = \abs{y}$, and $n\in\N$.
\end{definition}
Observe that for probabilistic functionalities, the simulator needs to generate a joint distribution of $(\view_i^\pi(x,y), \out^\pi(x,y))$. We can obtain a simpler security formulation for deterministic functionalities:
\begin{description}
\item[Correctness,] meaning that the output of the parties is correct. Formally, it requires that there exists a negligible function $\mu$ such that for every $x,y\in\{0,1\}^*$ and every $n$
    $$\Pr[\out^\pi(x,y,n)\neq f(x,y,n)]\leq\mu(n)$$
\item[Privacy] requires that there exists PPT $\calS_1$ and $\calS_2$ such that
\begin{align*}
    \{\calS_1(1^n,x,f_1(x,y))\}_{x,y,n} \stackrel{c}{\equiv} \{\view^\pi_1(x,y,n)\}_{x,y,n} \\
    \{\calS_2(1^n,y,f_2(x,y))\}_{x,y,n} \stackrel{c}{\equiv} \{\view^\pi_2(x,y,n)\}_{x,y,n} \\
\end{align*}
\end{description}
\begin{remark} There are many problemss that become trivial in the case of semi-honest adversaries. Such problems include zero knowledge, commitment and coin-tossing.
\end{remark}
\subsection{Oblivious Transfer for Semi-Honest Adversaries}
The bit oblivious transfer functionality is defined by $f((b_0,b_1), \sigma )=(\lambda,b_\sigma)$, where $b_0,b_1\in\{0,1\}$ and $\lambda$ denotes empty string.
\subsubsection{Background and Tools}
\begin{definition}[Trapdoor Permutations]
Trapdoor permutations is a collection of functions $\{f_\alpha\}_\alpha$ accompanied by four PPT algorithms $I,S,F,F^{-1}$ such that:
\begin{enumerate}
\item $I(1^n)$ select a random $n$-bit index $\alpha$ of a premutation $f_\alpha$ and a corresponding trapdoor $\tau$. Let $I_1(1^n)\equiv\alpha$.
\item $S(\alpha;r)$ samples an (almost uniform) element in the domain of $f_\alpha$. We assume $r\in\{0,1\}^n$.
\item $F(\alpha,x)=f_\alpha(x)$
\item $F^{-1}(\tau,y)=f^{-1}_\alpha(y)$
\end{enumerate}
\end{definition}
\YHnote{Need to check the security definition of T.P.}

\begin{definition}[Enhanced Trapdoor Permutations] A collection of {\sf trapdoor permutations} is a collection of {\sf enhanced trapdoor permutations} if for every non-uniform PPT adversary $\calA$ there exists a negligible function $\mu(\cdot)$ such that for every $n$,
$$\Pr[\calA(1^n,\alpha,r)=f^{-1}(S(\alpha;r))]\leq\mu(n)$$
where $\alpha\leftarrow I_1(1^n)$ and $r\stackrel{R}{\leftarrow}\{0,1\}^n$.
\end{definition}
\begin{definition}[Hard-Core Predicate] We say that $B$ is a {\sf hard-core predicate} of $(I,S,F,F^{-1})$ if for every non-uniform PPT adversary $\calA$ there exists a negligible function $\mu(\cdot)$ such that for every $n$,
$$\Pr[\calA(1^n,\alpha,r)=B(\alpha, f^{-1}(S(\alpha;r)))]\leq\frac{1}{2}+\mu(n)$$
\end{definition}
\begin{adjustbox}{minipage=\linewidth,fbox}
\begin{protocol}[Bit Oblivious Transfer]$ $
    \begin{description}
        \item[Inputs.] $P_1$ has $(b_0,b_1)$ and $P_2$ has $\sigma\in\{0,1\}$. Both have $(I,S,F,F^{-1})$ and corresponding hard-core predicate $B$.
        \item[The Protocol.] $ $\newline\newline
        \begin{adjustbox}{minipage=0.6\linewidth}
            \begin{tabular}{lcc}
            $P_1((b_0,b_1);r_1)$ & & $P_2(\sigma;(r_0^2,r_1^2))$ \\
            \\
            $(\alpha,\tau)\gets I(1^n;r_1)$ & \rextlinearrow{\alpha}{24} & \\
            & & $x_\sigma\gets S(\alpha;r_\sigma^2)$\\
            & & $y_{1-\sigma}\gets S(\alpha;r_{1-\sigma}^2)$\\
            & & compute $y_\sigma = F(\alpha,x_\sigma) $\\
            & \lextlinearrow{y_0,y_1}{24} & \\
            compute $x_0=F^{-1}(\tau,y_0)$ & & \\
            $x_1=F^{-1}(\tau,y_1)$ & & \\
            and \\ \\
            $\beta_0=B(\alpha,x_0)\oplus b_0$ & \rextlinearrow{\beta_0,\beta_1}{24}\\
            $\beta_1=B(\alpha,x_1)\oplus b_1$ & & compute $b_\sigma=B(\alpha,x_\sigma)\oplus\beta_\sigma$ \\
            \end{tabular}
        \end{adjustbox}
    \end{description}
\end{protocol}
\end{adjustbox}
\vspace{2mm}

\begin{algorithm}
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}
$S_1(1^n,(b_0,b_1);r,r_0,r_1)$\;
\Input{The input of $P_1$ and the ideal functionality output $f_1(\cdot,\cdot)$.}
\Output{A simulated view close to real view of $P_1$.}
\caption{Simulator of corrupted $P_1$.} \label{alg:bot-p1-sim}
Initialize $P_1$ with random tape $r$\;
Computes $(\alpha,\tau)\gets I(1^n;r)$\;
Computes $y_0\gets S(\alpha;r_0), y_1\gets S(\alpha;r_1)$\;
Output $((b_0,b_1),r;(y_0,y_1))$\;
\end{algorithm}

\begin{algorithm}
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}
$S_2(1^n,\sigma,b_\sigma,;r,r_0,r_1)$\;
\Input{The input of $P_2$ and the ideal functionality output $f_2(\cdot,\cdot)$.}
\Output{A simulated view close to real view of $P_2$.}
Initialize $P_2$ with random tape $(r_0,r_1)$\;
Computes $(\alpha,\tau)\gets I(1^n;r)$\;
Computes $x_\sigma\gets S(\alpha;r_\sigma), y_{1-\sigma}\gets S(\alpha;r_{1-\sigma})$\;
Set $x_{1-\sigma}=F^{-1}(\tau,y_{1-\sigma})$\;
Compute $\beta_\sigma=B(\alpha,x_\sigma)\oplus b_\sigma$\;
$\beta_{1-\sigma}=B(\alpha,x_{1-\sigma})$\;
Output $(\sigma,r_0,r_1;\alpha,(\beta_0,\beta_1))$\;

\caption{Simulator of corrupted $P_2$.} \label{alg:bot-p2-sim}
\end{algorithm}

\begin{description}
\item[$P_1$ is currupted.] Construct simulator $S_1$ as Algorithm \ref{alg:bot-p1-sim}. \\
We argue that the output of $S_1$ is statistically close to the view of corrupted $P_1$ with random tape equals to $r$. The simulator has no information about $P_2$'s input $\sigma$, so it cannot compute $y_\sigma=F(\alpha,x_\sigma)$. However, the definition of trapdoor permutation states that the output of $S(\alpha)$ is almost uniform. Thus,
    $$\{(F(\alpha,x_0),y_1)\}\stackrel{s}{\equiv}\{(y_0,y_1)\}\stackrel{s}{\equiv}\{(y_0,F(\alpha,x_1))\}$$
where $x_0,x_1,y_0,y_1$ are sampled by $S(\alpha)$ with independent randomness. This implies
$$\{S_1(1^n,(b_0,b_1))\}\sequiv\{\view^\pi_1((b_0,b_1),\sigma)\}$$
\begin{remark}
Step 1. of the simulator is necessary since it binds the view of simulator with the real view of $P_1$.
\end{remark}
\item[$P_2$ is corrupted.] Construct simulator $S_2$ as Algorithm \ref{alg:bot-p2-sim}:

\end{description}

\section{Zero Knowledge}
\subsection{Notations}
In this section, the {\it security parameter} is set to be the length of common input, namely $n=\abs{x}$. Let $A$ and $B$ be a probabilistic polynomial-time machine. We denote by $\out_B(A(x,y,r_A),B(x,z,r_B))$ the output of party $B$ in an interactive execution with party $A$, on public input $x$, where $A$ has auxiliary-input $y$ and random-tape $r_A$, and $B$ has auxiliary input $z$ and random-tape $r_B$.
\begin{definition}[Interactive Proof System] {\it(Informal)} An interactive proof system for a language $L$ involves a prover $P$ and a verifier $V$. The prover $P$ tries to convince $V$ that the common input $x$ is in language $L$. There are two properties for such a proof system:
\begin{enumerate}
\item {\it Completeness:} Exists honest $P$ such that $\out_V(P(x,w,r_P),V(x,r_V))=1$ with overwhelmly high probability on input $x\in L$.
\item {\it Soundness:} For all (cheating) prover $P^*$, $\out_V(P^*(x,z,r_P),V(x,r_V))=1$ with at most negiligible probability on input $x\notin L$.
\end{enumerate}
\end{definition}

\begin{definition}[Black-box Computational Zero Knowledge] Let $(P,V)$ be an interactive proof system for an $\NP$-language $L$, and let $R_L$ be the $\NP$-relation. We say that $(P,V)$ is {\sf black-box computational zero knowledge} if there exists a PPT oracle machine $\simu$ such that for every PPT algorithm $V^*$, it holds that:
$$\{\out_{V^*}(P(x,w),V^*(x,z))\}_{(x,w)\in R_L,z\in\{0,1\}^*}\cequiv\{\simu^{V^*(x,z,r,\cdot)}(x)\}_{x\in L,z\in\{0,1\}^*}$$
where $r$ is uniformly distributed, and where $V^*(x,z,r,\cdot)$ denotes the next-message function of $V^*$ when the common input $x$, auxiliary input $z$ and random-tape $r$ are fixed.
\end{definition}
We only consider the output of $V^*$ in our definition, due to the fact that there exists an adversarial $V^*$ that outputs its view. Thus one may equivanlently consider the view of the verifier and its output.
\begin{remark} Noted that we only care the distribution when $(x,w)\in R_L$. Why?
\end{remark}
\begin{remark} We fix the random tape of the $V^*$. In most case, this does not help since the adversary can ignore the random-tape and use a pseudorandom runction applied to its history with an internally hardcoded key.
\end{remark}

\subsection{Preliminaries - Commitment Schemes}
Let $\com$ be a non-interactive perfectly binding commitment scheme. Let $c=\com(x;r)$ denote a commitment to $x$ using randomness $r$ omitting the security parameter. Let $\com(x)$ denote a commitment using uniform randomness. Let $\decom(c)$ denote the decommitment value of $c$; if $c=\com(x;r)$ then $\decom(c)=(x,r)$.
There are two properties of a commitment scheme:
\begin{enumerate}
\item {\it (Computational) Hiding.} Informally, it states that the commitments to different strings are (computationally) indistinguishable. For bit commitmens, it means $\calC_0\cequiv\calC_1$ where $\calC_b\equiv\{\com(b;U_n)\}_{n\in\N}$.
\item {\it (Perfect) Binding.} All commitments of different values are disjoint; for all $x_1\neq x_2$ it holds that $\calC_{x_1}\cap\calC_{x_2}$ where $\calC_{x}=\{c|\exists r:c=\com(x;r)\}$.
\end{enumerate}
\begin{description}
\item[LR-security of commitments.] Define the oracle as $LR^b_{\com}(x_0,x_1)=\begin{cases}\com(x_b) & \text{if } \abs{x_0}=\abs{x_1},\\ \perp & \text{otherwise} \end{cases}$. The experiment is as follows:
\begin{description}
\item[Experiment ${\sf LR}$-commit$_{\com,\calA}(1^n)$:]$ $
\begin{enumerate}
\item Choose a random $b\gets\{0,1\}$.
\item Set $b'\gets\calA^{{\sf LR}^b_{\com}(\cdot,\cdot)}(1^n)$.
\item Output 1 iff $b'=b$.
\end{enumerate}
\end{description}
\end{description}
\begin{theorem}
If $\com$ is a {\it non-interactive perfectly-binding commitment scheme}, then for every non-uniform PPT adversary $\calA$ there exists a negligible function $\mu(\cdot)$ such that
$$\Pr[\text{\sf LR-commit}_{\com,\calA}(1^n)=1]\leq\frac{1}{2}+\mu(n).$$
\end{theorem}
\subsection{Non-Constant Round Zero Knowledge}

\begin{adjustbox}{minipage=1\linewidth,fbox}
\begin{protocol}[Zero-Knowledge Proof for 3-Coloring]$ $
    \begin{description}
        \item[Common input.] a graph $G=(V,E)$ with $V=\{v_1,\cdots,v_n\}$
        \item[Auxiliary input for $P$.] a coloring of the graph $\psi:V\to\{1,2,3\}$ such that 
        
        for every $(v_i,v_j)\in E$ it holds that $\psi(v_i)\neq\psi(v_j)$
        \item[The proof system:] Repeating the following $n\cdot\abs{E}$ times:
        $ $\newline\newline
        \begin{adjustbox}{minipage=0.6\linewidth}
            \begin{tabular}{lcl}
            $P(G,\psi;r_P)$ & & $V(G;r_V)$ \\
            \\
            Select a random permutation \\
            $\pi$ over $\{1,2,3\}$, define \\
            $\phi(v)=\pi(\psi(v))$ for all $v\in V$.\\
            Computes $c_i=\com(\phi(v_i))$ \\
            for all $i\in[n]$ & \rextlinearrow{(c_1,\cdots,c_n)}{24} & \\
            & & $e\in_R E$\\
            & \lextlinearrow{e}{24} &\\ 
            Let $e=(v_i,v_j)$, send \\
            & \rextlinearrow{\decom(c_i),\decom(c_j)}{24} & \\
            & & Check $\phi(v_i)$ and $\phi(v_j)$ \\
            & & is valid and $\phi(v_i)\neq\phi(v_j)$.\\
            & & if not, output 0. \\
            \end{tabular}
        \end{adjustbox}
        \\ \\
        If all checks pass in all iterations, the verifier outputs 1.
    \end{description}
    \label{proto:zk-3-color-nonconstant}
\end{protocol}
\end{adjustbox}
\\ \\
Regarding the {\it soundness} of the proof system. In each iteration, the cheating prover can only success if it guess the query of honest verifier, the probability of guessing right is $\frac{1}{\abs{E}}$.
\subsubsection{The Rewinding Technique and Formal Proof of Security}
We begin by giving an intuition of the simulator process when we model the commitments as perfect envelopes that reveal nothing until opened (in constrast to our real $\com$, which is computationally-hiding). 
\begin{enumerate}
\item The simulator first guess a random edge $e=(v_i,v_j)\in_R E$ with the hope that the verifier will query that edge. 
\item The simulator then sends the verifier commitments to a coloring such that $v_i$ and $v_j$ is given different colors in $\{1,2,3\}$ and the rest is set to zero.
\item If the verifier replies with the edge $e'=e$, the simulator opens the envelopes of $v_i$ and $v_j$ and the simulation of this iteration is complete.
\item Otherwise the simulator rewinds the verifier to the beginning of the iteration and tries again with fresh randomness.
\end{enumerate}
Note that this simulator output a view that is identical to the real view within {\bf expected} polynomial-time, while the security definition requires $\simu$ to be a PPT algorithm. Therefore, some modifications are required as we will see in Algorithm \ref{alg:zk-3-color-nonconstant-sim}.
\begin{description}[leftmargin=0cm]
\item[On dealing with aborts.] One strategy is to state that if the verifier returns an illegal value, then the honest prover halts. However, in this case, it is easier for our proof of security to state that the honest prover interpret any invalid reply as a default edge.
\end{description}
The expected number of repetitions in one iteration is $\abs{E}$, and probability that more than $n\cdot\abs{E}$ repetitions are needed is negligible. 
\begin{remark} How is rewinding possible? And why does the existence of simulator not contradict soundness?
\end{remark}

\begin{algorithm}
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}
$\simu^{V^*(x,z,r,\cdot)}(G;r)$\;
\Input{$G=(V,E)$, with $V=\{v_1,\cdots,v_n\}$}
\Output{A simulated view close to real view of $V^*$.}
Initializes the message history transcript $\vec{m}\gets\lambda$\;
\Repeat{$n\cdot\abs{E}$ times}{
    \For{$j=1,\cdots,n\cdot\abs{E}$}{
        $(v_k,v_\ell)\in_R E$\;
        Choose $\phi(v)$ such that $\phi(v_k)\in_R\{1,2,3\}$ and $\phi(v_\ell)\in_R\{1,2,3\}\backslash\{\phi(v_k)\}$. For all other $v_i\in V\backslash\{v_k,v_\ell\},\phi(v_i)=0$\;
        \For{$i=1,\cdots,n$}{$c_i=\com(\phi(v_i))$}
        "Send" $(c_1,\cdots,c_n)$ to $V^*$. and Let $e\in E$ be the reply\;
        \If{$e=(v_k,v_\ell)$}{
            Update the message history transcript as
            $\vec{m}\gets(\vec{m},(c_1,\cdots,c_n),(\decom(c_k),\decom(c_\ell)))$\;
            $\bf break$
        }
        \Else{
            "rewind" the verifier to the beginning of for loop\;
        }
    }
    {\bf Output} $\perp$
}
{\bf Output} $\vec{m}$\;
\caption{Simulator of Protocol \ref{proto:zk-3-color-nonconstant}.} \label{alg:zk-3-color-nonconstant-sim}
\end{algorithm}

\begin{theorem}
Let $\com$ be a {\it perfectly-binding commitment scheme with security for non-uniform adversaries.} Then, protocol \ref{proto:zk-3-color-nonconstant} is black-box computational zero knowledge.
\end{theorem}
\begin{proof}
Our goal is to proof that Algorithm \ref{alg:zk-3-color-nonconstant-sim} generates a transcript that is indistinguishable from a real transcript. We begin by constructing an alternative simulator $\simu'$ which is given a valid coloring $\psi$ as auxiliary input. We can see that:
$$\{\out_{V^*}\langle P(G,\psi),V^*(G,z) \rangle \}\equiv\{\simu'^{V^*(G,z,r,\cdot)}(G,\psi)|\simu'^{V^*(G,z,r,\cdot)}(G,\psi)\neq\perp\}$$
This is achieved by the power of rewinding. Now since the probability that $\simu'$ fails in all $n\cdot\abs{E}$ repetitions is $(1-\frac{1}{\abs{E}})^{n\cdot\abs{E}}<e^{-n}$. There are $n\cdot\abs{E}$ iterations, by union bound we have, $\simu'$ output $\perp$ with probability less than $n\cdot\abs{E}\cdot e^{-n}$. This implies that
$$\{\simu'^{V^*(G,z,r,\cdot)}(G,\psi)|\simu'^{V^*(G,z,r,\cdot)}(G,\psi)\neq\perp\}\cequiv\{\simu'^{V^*(G,z,r,\cdot)}(G,\psi)\}$$

The remaining step is to prove the output of $\simu$ and $\simu'$ are computationally indistinguishable:
$$\{\simu'^{V^*(G,z,r,\cdot)}(G,\psi)\}\cequiv\{\simu^{V^*(G,z,r,\cdot)}(G)\}.$$
Assume toward contradiction, there exists a PPT verifier $V^*$, a PPT distinguisher D and a polynomial $p(\cdot)$ such that for an infinite sequence $(G,\psi,z)$ where $(G,\psi)\in R$ and $z\in\{0,1\}^*$,
$$\abs{\Pr[D(G,\psi,z,\simu'^{V^*(G,z,r,\cdot)}(G,\psi))]-\Pr[D(G,\psi,z,S^{V^*(G,z,r,\cdot)}(G))]}\geq\frac{1}{p(n)}$$
Now we construct a non-uniform PPT adversary $\calA$ for the commitment experiment {\sf LR-commit} as follows:
\begin{algorithm}
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}
$\calA^{{\sf LR}^b_{\com}(\cdot,\cdot),\simu'(\cdot,\cdot),V^*(\cdot,\cdot,\cdot;\cdot)}(1^n,(G,\psi,z);r)$\;
\Input{security parameter $n$ and auxiliary input $(G,\psi,z)$ where $\abs{G}=n$}
\Output{a guess of $b$ from ${\sf LR}^b_\com$}
Initialize $V^*$ as $V^*(G,z,r;\cdot)$ where $r$ is uniformly random $G,z$ from auxiliary input\;
Runs the instructions of $\simu'$ with input $(G,\psi)$ and oracle $V^*(x,z,r;\cdot)$ with some modifications. In particular, line 8 in Algorithm \ref{alg:zk-3-color-nonconstant-sim} is changed as follows:
\begin{enumerate}
\item For the randomly chosen edge $e=(v_k,v_\ell)$, $c_k=\com(\phi(v_k))$ and $c_l=\com(v_\ell)$ as the original algorithm.
\item For all other $i\in\{1,\cdots,n\}\backslash\{k,\ell\}$, $c_i\gets LR^b_\com(0,\phi(v_i))$.
\end{enumerate}
{\bf Output} $D(\simu'^{V^*(G,z,r;\cdot)}(G,\psi))$\;
\caption{Adversary of {\sf LR-commit}} \label{alg:zk-3-color-reduction}
\end{algorithm}

We can see that if $b=1$:
\begin{align*}
    \Pr[\text{\sf LR-commit}_{\com,\calA}=1|b=1]=\Pr[D(G,z,\simu'^{V^*(G,z,r;\cdot)}(G,\psi))=1]
\end{align*}
and if $b=0$:
\begin{equation*}
    \Pr[\text{\sf LR-commit}_{\com,\calA}=1|b=0]=\Pr[D(G,z,\simu^{V^*(G,z,r;\cdot)}(G))=1]
\end{equation*}
We have
\begin{align*}
    \Pr&[\text{\sf LR-commit}_{\com,\calA}=1] \\
    &=\frac{1}{2}\Pr[\text{\sf LR-commit}_{\com,\calA}=1|b=1]+\frac{1}{2}\Pr[\text{\sf LR-commit}_{\com,\calA}=1|b=0] \\
    &=\frac{1}{2}\Pr[D(G,z,\simu'^{V^*(G,z,r;\cdot)}(G,\psi))=1]+\frac{1}{2}\Pr[D(G,z,\simu^{V^*(G,z,r;\cdot)}(G))=0] \\
    &=\frac{1}{2}\Pr[D(G,z,\simu'^{V^*(G,z,r;\cdot)}(G,\psi))=1]+(1-\frac{1}{2}\Pr[D(G,z,\simu^{V^*(G,z,r;\cdot)}(G))=0]) \\
    &=\frac{1}{2} + \frac{1}{2}(\Pr[D(G,z,\simu'^{V^*(G,z,r;\cdot)}(G,\psi))=1]-\Pr[D(G,z,\simu^{V^*(G,z,r;\cdot)}(G))=1]) \\
    &\geq\frac{1}{2}+\frac{1}{2p(n)}
\end{align*}
This contradict the security of $\com$. Thus we have $$\{\out_{V^*}(P(G,\psi),V^*(G,z))\}\cequiv\{\simu^{V^*(G,z,r;\cdot)}(G)\}$$
\end{proof}

\subsection{Constant-Round Zero Knowledge}
Simply runs $n\cdot\abs{E}$ iteration in parallel is not working. The simulator will need to guess all $N\stackrel{def}{=} n\cdot\abs{E}$ edges correctly to success. The probability of guessing correctly is $\abs{E}^{-n\cdot\abs{E}}$, which is exponentially small. Note that rewinding doesn's solve this problem. The adversaries can simply choose a new randomness each time. In fact, Goldreich and Krawczyk showed that this paralle protocol is not {\it black-box zero-knowledge}, and no constant-round public-coin proof for a language not in ${\sf BPP}$ is boack-box zero-knowledge. Althougth there are no known constructions of adversaries, the lack of known attack is not sufficient to conclude that a protocol is secure. Thus, an alternative protocol is needed.

The solution presented by Goldreich and Kahan is to simply have the verifier commit to its query before the prover sends its commitments. This prevents a malicious verifier from changing its query during rewinding. Details appear in Protocol \ref{proto:zk-3-color-constant}. \\ \\
\begin{adjustbox}{minipage=1\linewidth,fbox}
\begin{protocol}[The Goldreich-Kahan Proof System]$ $
    \begin{description}
        \item[Common input.] a graph $G=(V,E)$ with $V=\{v_1,\cdots,v_n\}$
        \item[Auxiliary input for $P$.] a coloring of the graph $\psi:V\to\{1,2,3\}$ such that \\ 
        for every $(v_i,v_j)\in E$ it holds that $\psi(v_i)\neq\psi(v_j)$
        \item[Primitives] Let $\com$ be an non-interactive perfectly-binding commitment scheme,\\ $\com_h$ be a two-round perfectly-hiding commitment scheme. 
        \item[The proof system:] Repeating the following $n\cdot\abs{E}$ times:
        $ $\newline\newline
        \begin{adjustbox}{minipage=0.6\linewidth}
            \begin{tabular}{lcl}
            $P(G,\psi;r_P)$ & & $V(G;r_V)$ \\
            \\
            Send the first message, denoted 
            \\by $\alpha$ of $\com_h$ & \rextlinearrow{\alpha}{15} & \\
            & & choose $N\stackrel{def}{=}n\cdot\abs{E}$ random \\
            & & edges $q=(e_1,\cdots,e_N)$, \\
            & & where $e_i\in E$ \\
            &\lextlinearrow{c}{15}& $c=\com_h(q)$\\
            Continue as basic protocol \ref{proto:zk-3-color-nonconstant}&&\\
            & \rextlinearrow{\com(\phi(v))}{15} & \\
            & \lextlinearrow{\decom(c)}{15}& send decommitmet of $c$\\
            {\bf If} the decommitment is invalid \\
            {\bf abort}& &\\
            {\bf Otherwise} send the decommitment \\
            of edges & \rextlinearrow{\decom(v)}{15}& If all checks pass outputs 1\\
            \end{tabular}
        \end{adjustbox}
        \\
    \end{description}
    \label{proto:zk-3-color-constant}
\end{protocol}
\end{adjustbox}
\\ \\
First thought of a possible simulator is:
\begin{enumerate}
\item $\simu$ sends $alpha$ to $V^*$
\item $\simu$ receives commitment $c$ from $V^*$
\item $\simu$ sends $V^*$ garbage commitments and receives its decommitment. If the decommitment is not valid, it aborts. Otherwise, denote the decommitted string by 
$q=(e_1,\cdots,e_N)$.
\item $\simu$ rewinds $V^*$, send a new $\com(\phi(v))$ that suit $q$. Repeat this step until $V^*$ send a valid decommitment
\item $\simu$ sends $V^*$ the decommitment to the nodes on the committed edge and outputs whatever $V^*$ outputs.
\end{enumerate}
There are two issues in this simple simulator. First, since the commitment to $q$ is perfectly hiding and thus only {\it computationally-binding}. It is possible that the $V^*$ decommits to a valid $q'\neq q$. Second, we are not able to show that the simulator is running in expected polynomial-time. Let $\epsilon$ denote the probability that $V^*$ does not abort. At first glance, one may conclude that the expected running time of the simulator is $(1-\epsilon)+\epsilon\cdot\frac{1}{\epsilon}$. However this is only in the case that commitment is modeled as "perfect envelopes". The true running is:
$$poly(n)\cdot(1-\epsilon(n)+\epsilon(n)\cdot\frac{1}{\epsilon(n)-\mu(n)}),$$
which might be exponential in $n$.
\begin{theorem} Let $\com_h$ and $\com$ be {\it perfectly-hiding} and {\it perfectly-binding} commitment schemes, respectively, with security in the presence of non-uniform PPT adversaries. Then Protocol \ref{proto:zk-3-color-constant} is black-box computational zero knowledge with an expected polynomial-time simulator.
\end{theorem}
\begin{proof}
The simulator is stated as Algorithm \ref{alg:zk-3-color-constant-sim}. We have three claims to complete our proof.
\begin{claim} Algorithm \ref{alg:zk-3-color-constant-sim} runs in expected polynomial time in $n$.
By Chernoff bound, we have $\widetilde{\epsilon}$ is not within a constant factor of $\epsilon(n)$ is at most $2^{-n}$.
Consider two cases:
\begin{enumerate}
\item $\widetilde{\epsilon}$ is not within a constant factor of $\epsilon(n)$.
	The running-time is bounded by $2^{n}$ and this happens with probability $2^{-n}$. This add a total $poly(n)$ to expected running-time.
\item $\widetilde{\epsilon}/\epsilon=O(1)$.
We can bound the expected running-time of $\simu$ by
$$poly(n)\cdot\epsilon(n)\cdot(\frac{12n}{\epsilon(n)}+n\cdot\frac{n}{\widetilde{\epsilon}})=poly(n)$$
\end{enumerate}
\end{claim}
\begin{claim} The probability that Algorithm \ref{alg:zk-3-color-constant-sim} outputs {\sf fails} is negligible.
Notice that:
$$\Pr[\simu \text{outputs \sf fails}]=\Pr[\text{does not obtain vaild decommitment in the loop}]+\Pr[\text{runs for }2^n\text{steps}]$$
We already saw that $\simu$ runs in expected poly-time, therefore the probability that it runs for $2^n$ steps is negligible.
Now consider the case the $\simu$ does not obtain valid in all $n\cdot\frac{n}{\widetilde{\epsilon}}$ attemps. Recall that $\epsilon(n)$ denotes the probability that $V^*$ decommits when given commitments to all zeros. Next there exists an negligible function $\mu(\cdot)$ such that $V^*$ decommits when given commitments in line 20 of Algorithm \ref{alg:zk-3-color-constant-sim}.
\end{claim}

\begin{algorithm}
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}
$\simu^{V^*(x,z,r,\cdot)}(G;r)$\;
\Input{$G=(V,E)$, with $V=\{v_1,\cdots,v_n\}$}
\Output{A simulated view close to real view of $V^*$.}
"Send" $V^*$ the first message of $\com_h$\;
"Receive" from $V^*$ an commitment $c$ to some query string $q=(e_1,\cdots,e_N),N=n\cdot\abs{E}$ and receive back its reply\;
"Send" $V^*$ $N$ vectors of $n$ commitments to $0$\;
\If{$V^*$ {\bf aborts} or $\decom_h(c)$ is invalid}{
    {\bf Output} $\perp$
}\Else{
    
    Let $q=(e_1,\cdots,e_N)$ be the decommitted value.\;
    $m\gets 0$\;
    $ctr\gets 0$
    \While{$m<12n$}{
    	$ctr\gets ctr+1$
    	execute {\bf Step 4}\;
	\If{$\decom_h(c)$ is valid}{
		$m\gets m+1$\;
	}
    }
    $\widetilde{\epsilon}\gets \frac{m}{ctr}$\;
    \For{$i=1,\cdots,n$}{
    \For{$j=1,\cdots ,n / \widetilde{\epsilon} $} {
    Generate $N$ vectors of commitments $\vec{c_1},\cdots,\vec{c_N}$ as original protocol.\;
    	\If{$V^*$ provides a valid decommitment to $q$}{
		{\bf break}\;
    	}
	\If{$V^*$ provides a valid decommitment to $q'\neq q$}{
		{\bf output} {\sf ambiguous}\; {\bf halts}\;
	}
	\If{the total running time $> 2^{-n}$}{{\bf output} {\sf fails}\;}
    }}
    Completes the proof by handing $V^*$ decommitments.
}

\caption{Simulator of Protocol \ref{proto:zk-3-color-constant}.} \label{alg:zk-3-color-constant-sim}
\end{algorithm}

\end{proof}


\insertbibliography{crypto}
\nocite{*} 